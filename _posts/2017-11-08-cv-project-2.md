---
author: Dakota Hawkins
layout: post
title: CV Project 2
cover: solve_smol.png
date: 2017-10-08 17:55:00
categories: posts
---

## Automating Centroid Detection of Primary Mesenchyme Cells in Confocal Images
  
Metastatic events in tumor cells account for roughly 90% of cancer-related deaths. However, metastasis is still poorly understood. To shine light on foundational events present during metastatic transitions, my lab studies the movement and pattern formation of primary mesenchyme cells in developing sea urchins. Cell migration and pattern formation are largely signal-dependent events, where signals from surrounding cells induce patterning and/or motility. Thus, positional information that determines *where* cells exist and *where* signals originate from are integral in understanding many cellular events. However, determining centers for individual cells is time consuming, and becomes impractical with prolific cell types.  The goal of this project is to utilize computer vision and machine learning techniques to automatically detect flourescently tagged cells and return their 3-dimensional centroids in cofocal images. Specifically, I will be using images of stained primary mesenchyme cells (PMCs) in developing sea urchins. Images will be provided by Cynthia Bradham's lab at Boston University. This is an individual project.

### Input Images
Confocal images are partial volume images where cross sectional images are taken at different depths. Slices are then projected to create a three-dimensional image, as seen below.

![Embryo Slice](/images/2d_example.png)
*Embryo Slice*

![Projected Embryo](/images/3d_example.png)
*Projected Embryo*

To recognize cells in two-dimensional images, I will first create a labelled dataset of subimages containing PMCs and non-PMC samples. Subimages will be extracted and logged into a database using an in-house labeller I have recently developed, as shown below. For this project, each embryo has 27 image slices that comprise all cross sections. 375 seperate cells, across 7 embryos, have previously been identified and their centers extracted. These cells will form the basis of our dataset.

![Cell Labeller](/images/cell_labeller_example.png)
*Cell Labeller*

### Centroid Extraction

Three dimensional centroids -- *(x, y, z)* --  of cells will be extracted by first identifying cells in each two-dimensional slice, recording the diameter of each recognized cell, and tracking each recognized cell up *z*-stacks. Because PMCs are roughly spherical, finding local maxima for tracked radii along the z-axis should provide an accurate estimate for z-centers. Finding *xy* centers will then be trivial. 

Once a labelled dataset has been constructed, the labelled images and image features will be run through a support vector machine to identify cells. Because we've constructed a binary classifier, calculating the area under the ROC curve will be used to measure classifier performance.

Once centroids for each identified cell have been identified, per previous description, centroid accuracy will be assessed by calculating the sum of square errors for predicted centers.

### Previous Work

Previous work in the Bradham lab as been conducted on this project before. Most efforts looked to identify cells using traditional morphological analysis, such as watershed analysis, and circle detection. Unfortunately, these methods did not perform well enough to rely on for unlabelled datasets. The use of machine learning techniques will hopefully boost performance to an acceptable level.
